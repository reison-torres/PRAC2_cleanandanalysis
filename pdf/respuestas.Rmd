---
title: "Actividad: PRA2: Limpieza y análisis de datos"
author: "Reison A. Torres Urina"
date: "Diciembre 2019"
header-includes:
  - \usepackage[spanish]{babel}
output: 
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    includes:
      in_header: PRA2-header.html
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Detalles de la actividad  

## Descripción  

En esta practica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.  

## Objetivos

Los objetivos concretos de esta práctica son:  

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de
problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o
multidisciplinares.  

* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza
y validación) para llevar a cabo un proyecto analítico.  

* Aprender a analizar los datos adecuadamente para abordar la información contenida en
los datos.  

* Identificar la mejor representación de los resultados para aportar conclusiones sobre el
problema planteado en el proceso analítico.  

* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.  

* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.  

* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:  

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.  

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.  

# Solución

## Descripción del dataset  

### Carga de los datos

Cargamos el conjunto de datos que se encuentran en los archivos __train.csv__, __test.csv__ y __gender_submission.csv__ en formato CSV, y representan los datos de los pasajeros que abordaron el Titanic.

Estos datos estarán representados en R por un dataframe para facilitar la manipulación de los mismos en nuestro análisis.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# cargamos paquetes R que vamos a utilizar durante nuestro anlisis
  
if(!require(ggplot2)){
    #install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}

if(!require(ggpubr)){
    #install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}

library(dplyr)
#library(Hmisc)
#library(corrplot)

# Carga del dataset contenido en el archivo train.csv
titanic.train <- read.csv("../datos/train.csv",stringsAsFactors = FALSE, header=T, sep=",")
# Carga del dataset contenido en el archivo test.csv
titanic.test <- read.csv("../datos/test.csv",stringsAsFactors = FALSE, header=T, sep=",")
# Carga del dataset contenido en el archivo gender_submission.csv
titanic.test.survived <- read.csv("../datos/gender_submission.csv",stringsAsFactors = FALSE, header=T, sep=",")

```

### Descripción

Los datos seleccionados, fueron obtenidos del sitio de data science, [__www.Kaggle.com__](https://www.kaggle.com), en el encontramos una variedad de dataset Open Data. El conjunto de datos seleccionados para desarrollar esta actividad es [__Titanic: Machine Learning from Disaster__](https://www.kaggle.com/c/titanic), en este dataset encontramos, los datos de los pasajeros, que abordaron el Titanic en su viaje inaugural.

Los datos de este dataset se encuentran divididos en dos archivos train.csv con 891 observaciones y test.cvs con 418 observaciones para un total de 1309. El conjunto de datos esta descripto por un conjunto de 12 variables. Las característica presenten en este dataset, nos permitirá cumplir los objetivos propuestos en esta actividad. 

Variables contenidas en el dataset __train.csv__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.train)
```

Variables contenidas en el dataset __test.cvs__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.test)
```

Variables contenidas en el dataset __gender_submission.csv__:  
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(titanic.test.survived)
```  

Este dataset __gender_submission.csv__ contiene la variable de survived, que luego utilizaremos para agregar al dataset __titanic.test__.

A continuación describimos el conjunto de variables que conforman este dataset:  

* __PassengerId:__ Número consecutivo que identifica al pasajero.    
* __Name:__ Nombre del pasajero.
* __Sex:__ Define el xeso del pasajero.   
* __pclass:__ Nivel socioeconómico del pasajero (1st = Upper, 2nd = Middle, 3rd = Lower).  
* __age:__ Edad del pasajero en años.  
* __sibsp:__ Número de hermanos o cónyuges.  
* __parch:__ Número de hijos, padres.  
* __ticket:__ Número del boleto de abordaje.  
* __fare:__ Precio del boleto.  
* __cabin:__ Número de la cabina.  
* __embarked:__ Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton).  
* __survived:__ Pasajero superviviente (0 = No, 1 = Yes)


### Importancia y objetivos de los análisis


A partir de este conjunto de datos se plantea la problemática de determinar qué variables influyen más en la supervivencia de un pasajero en el naufragio del Titanic. Además, se podrá proceder a crear modelos de regresión  que permitan predecir si un pasajero sobrevive o no en función de sus características y contrastes de hipótesis que ayuden a identificar propiedades interesantes en las muestras que puedan ser inferidas con respecto a la población.  

Este tipo de análisis pueden ser utilizados por las aseguradoras del sector turístico, para determinar el riesgo que puede tener un turista al viajar en los trasatlánticos. Y asi poder ofreser las cobertura del seguro.

## Integración y selección de los datos de interés a analizar


### Integración

Con el fin de tener una estructura de datos coherente y única que contenga mayor cantidad de información, combinaremos los datos procedentes de los dataset train.csv y test.cvs. Luego realizaremos una fusión horizontal para añadir el atributo **survived**, debido a que el dataset **test.cvs** no presenta este atributo. Este valor será extraído  del dataset **gender_submission.csv**.


```{r echo=TRUE, message=FALSE, warning=FALSE}

# Realizamos una fusión horizontal entre los dataset titanic.test y titanic.test.survived para agregar el atributo survived
titanic.test <- inner_join(titanic.test, titanic.test.survived, by ="PassengerId")

#Creamos el dataset titanic.data con la combinacion de los datos de los dataset  titanic.train y titanic.test
titanic.data <- bind_rows(titanic.train,titanic.test) 

# Eliminamos los dataset temporales
rm(titanic.test.survived)
rm(titanic.test)
rm(titanic.train)

# Verificamos la estructura del dataset con los datos combinados
summary(titanic.data)
```

### Selección de los datos

La gran mayoría de las variables contenidas en el conjunto de datos corresponde con características de los pasajeros que abordaron el Titanic, por lo que serán tenidas en cuenta para realizar nuestro análisis. Sin embargo, podremos prescindir de las variables (**PassengerId**,**Name** y **Ticket**) dado que estos atributos no aportan una carasterisitica al pasajero, y no influye en la resolución de nuestro problema.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Eliminamos del dataset las variables "PassengerId" y "Name"
titanic.data <- titanic.data[,!(colnames(titanic.data) %in% c("PassengerId","Name","Ticket"))]

# Verificamos la estructura del dataset
summary(titanic.data)
```

## Limpieza de los datos

### Discretización y conversion de tipos de datos

Al cargar los archivos con la función read.csv(), esta de manera automática asigna el tipo de variable en el dataset, en ciertas ocasiones los tipos asignados, no son los correctos. A continuación visualizamos los tipos de variables asignados al dataset, para luego decidir si se requiere una conversión de tipo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Tipos de variables
titanic.data.ctype <- sapply(titanic.data,class)

titanic.data.ctype <- data.frame(variables = names(titanic.data.ctype),tipo = as.vector(titanic.data.ctype),stringsAsFactors = F)

titanic.data.ctype
rm(titanic.data.ctype)
```

En este paso realizamos un analisis sobre las variables, que en R han sido cargadas como continuas pero en realidad son discretas (factor).Para esto realizamos un análisis de discretizacion sobre los atributos, para identificar que variables tienen sentido discretizar.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#summary(titanic.data[,titanic.data.ctype[titanic.data.ctype$tipo == "numeric",]$variables])
# Identificar el número de clases que se encuentra en cada variable del dataset
apply(titanic.data,2, function(x) length(unique(x)))

```

Con el fin de facilitar la interpretar y comparar los resultados de diferentes grupos de datos, procedemos a discretizar a las variables con pocas clases:

```{r echo=TRUE, message=FALSE, warning=FALSE}

cols<-c("Survived","Pclass","Sex","Embarked")
for (i in cols){
  titanic.data[,i] <- as.factor(titanic.data[,i]) # Conversion de variable a tipo factor
}

levels(titanic.data[,"Survived"]) <- c("No","Si") 
levels(titanic.data[,"Pclass"]) <- c("Upper","Middle", "Lower")
levels(titanic.data[,"Embarked"]) <- c("?","Cherbourg", "Queenstown", "Southampton")

summary(titanic.data)
```

### Tratamientos de ceros o elementos vacíos

Los datos vacíos o no definidos pueden presentarse en distintos formatos, típicamente “”, ? ,“ “ o NA (Not Available en inglés), pero en algunos contextos pueden incluso tomar valores numéricos como 0 o 999.

A continuación inspeccionaremos, que atributos de nuestro dataset, tienen una cantidad alta de valores no disponibles o valores faltantes en los diferentes formatos  ("",?, " " o NA):


```{r echo=TRUE, message=FALSE, warning=FALSE}

# Funcion: Explorar atributos con valores faltante
# Parmetros:
# 1. dataset: conjunto de datos con los atributos a explorar
hasValoresFaltantes <- function(dataset){
  # Verificar si existen variables cuantitativas con valores NA
  variablesWithNA <- colSums(is.na(dataset))
  
  # Verificar si existen variables con cadenas vacias
  variablesWithEmpaty <- colSums(dataset=="")
  variablesWithEmpaty[is.na(variablesWithEmpaty)] <- 0
  
  # Verificar si existen variables con valores desconocidos ("?").
  variablesWithQuestionMark <- colSums(dataset=="?")
  variablesWithQuestionMark[is.na(variablesWithQuestionMark)] <- 0
  
  # Verificar si existen variables con valores desconocidos (" ").
  variablesWithSpace <- colSums(dataset==" ")
  variablesWithSpace[is.na(variablesWithSpace)] <- 0
  
  df <- data.frame(variables = names(variablesWithNA),"NA" = as.vector(variablesWithNA),stringsAsFactors = F)
  
  df = bind_cols(df,"Empaty" = as.vector(variablesWithEmpaty))
  df = bind_cols(df,"?" = as.vector(variablesWithQuestionMark))
  df = bind_cols(df,"Space" = as.vector(variablesWithSpace))
  
  df 
  #ls <- list(valoresFaltantes = df);
  #ls$totalMuestras <- dim(dataset)[1]
  #ls
}


```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verificar si existen variables con valores faltantes
hasValoresFaltantes(titanic.data)

```

Al observar el resultado del análisis anterior, podemos identificar que para las variables Age y Fare presenta  valores faltantes (NA). Para la variable Cabin se identifica que presenta una cantidad alta de valores faltantes en el formato vacío (""). y para la variable Embarked se identifica valores faltantes en el formato "?".

Llegados a este punto debemos decidir cómo manejar estos registros que contienen valores desconocidos:

Para el  atributo __Embarked__ realizamos un análisis de proporción de valores faltantes y lo actualizaremos en función del valor mas frecuente. Existen 2 casos con valor faltante con formato "?", con una proporción del 0.15%, el valor más frecuentes es "Southampton" con una proporción del 56.98% .


```{r echo=TRUE, message=FALSE, warning=FALSE}
arrange(data.frame(round(prop.table(table(titanic.data$Embarked)),4)*100),-Freq)

# actualizamos los valores faltantes con el valor más frecuente
titanic.data$Embarked[titanic.data$Embarked=="?"] <- "Southampton"
titanic.data$Embarked <- droplevels(titanic.data$Embarked) #Eliminamos los niveles no utilizados (?)
```

Para el  atributo __Cabin__ realizamos un análisis de proporción de valores faltantes. Existen 1014 casos con valor faltante con formato vacío (""), con una proporción del 77.46%, esto corresponde a más de la mitad de las observaciones. Si intentamos completar los valores faltantes, por alguna de las técnicas de imputación de valores perdidos, debido a la alta cantidad de valores faltantes en este atributo, nos puede generar sesgos en los datos de este atributo. De acuerdo a esto, se decide eliminar el atributo __Cabin__ del dataset en estudio.


```{r echo=TRUE, message=FALSE, warning=FALSE}
data.frame(Total=sort(colSums(titanic.data == ""), decreasing = TRUE),
           Porcentaje = sort(round(colMeans(titanic.data == "")*100, digits = 2), decreasing = TRUE))["Cabin",]

# Eliminamos la variable Cabin
titanic.data <- titanic.data[, !(names(titanic.data) %in% c("Cabin"))]

```

Como podemos observar las variables __SibSp__, __Parch__ y __Fare__, presenta datos con valores igual a cero, pero para las variables __SibSp__, __Parch__ este valor cero significa que no tienen familiares abordo, de acuerdo a esto el valor cero tiene significado para los datos, y no serán gestionados.

Para la variable __Fare__ los valores ceros podria significar un error de datos faltantes, ya que tienen un numero de ticket asignado, o tambien podriamos decir que este cero equivale a que estos ticket fueron entregados por un premio. Para esta actividad asumiremos que es un error y lo consideraremos como valores faltantes.

Calculamos la proporciona de valores ceros en la variable __Fare__, y los remplazamos por el formato de valor faltante (NA), para luego predecir estos valores con el método kNN. Existen 17 casos con valor faltante con formato vacío (0), con una proporción del 1.3%.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Proporcion en 
data.frame(Var = c("Fare"),
           Total = length(titanic.data$Fare[titanic.data$Fare == 0 & !is.na(titanic.data$Fare)]),
           Porcentaje = round((length(titanic.data$Fare[titanic.data$Fare == 0 & !is.na(titanic.data$Fare)])/dim(titanic.data)[1])*100,2))

titanic.data$Fare [titanic.data$Fare == 0 & !is.na(titanic.data$Fare)]<- NA

str(titanic.data)
```
Para los  atributo __Fare__ y __Age__ realizamos un análisis de proporción de valores faltantes. Para el caso del atributo __Fare__, existe 18 caso con valor faltante con formato vacío (NA), con una proporción del 1.38%; Y para el atributo __Age__, existe 263 casos con valores faltantes con formato vacío (NA), con una proporción del 20.09%; Debido a que los datos presente en esta variable están un poco dispersos, utilizaremos métodos probalísticos para predecir los valores faltantes.


```{r echo=TRUE, message=FALSE, warning=FALSE}
#library(VIM)
if(!require(VIM)){
    #install.packages('VIM', repos='http://cran.us.r-project.org')
    library(VIM)
}
data.frame(Total=sort(colSums(is.na(titanic.data)), decreasing = TRUE),Porcentaje = sort(round(colMeans(is.na(titanic.data))*100, digits = 2), decreasing = TRUE))[c("Fare","Age"),]

# Para predecir los valores faltantes utilizaremos el metodo kNN
titanic.data.imp <- kNN(titanic.data)

# Imputamos los valores faltantes
titanic.data$Age <- titanic.data.imp$Age # Age
titanic.data$Fare <- titanic.data.imp$Fare #Fare
rm(titanic.data.imp)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Verificar si existen variables con valores faltantes
hasValoresFaltantes(titanic.data)

```



### Identificación y tratamiento de valores extremos

Los valores extremos (outliers) son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población. Con este análisis queremos identificar si el dataset contiene observaciones que están alejadas de su distribución normal, con el fin de evitar que estos valores puedan afectar de forma adversa los resultados de los análisis posteriores, al incrementar el error en la varianza de los datos y sesgar significativamente los cálculos y estimaciones.

Para identificar estos valores en el dataset, realizaremos un análisis por cuartiles, para las variables __Age__ y __Fare__. Debido a que el resto de variables pueden ser de tipo categóricas o texto no las incluiremos en este análisis.

Realizaremos un análisis de valores extremos para la variable numérica __Age__, realizando un análisis por quartiles:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# generar los quartiles que representan la distribución del conjunto de datos
summary(titanic.data$Age)

## Calculamos la relación inter quartil (IQR), Q3 - Q1 = IQR()
print(paste("Relación inter quartil (IQR): ",IQR(titanic.data$Age)),quote = FALSE)

# Grafico de boxplot
gf.boxplot <- boxplot(titanic.data$Age, main="Boxplot de la edad (Age)",
ylab="Age",col = "bisque")
```

Al inspeccionar las estadísticas arrojadas, para la variable __Age__, el valor mínimo es 0.17 y el Máximo es 80. Si analisamos  la diferencia entre Q1 y el Mínimo es de 20.83, y la diferencia entre Q3 y el Máximo es 42; cómo podemos ver la diferencia de Q3 y el máximo es mayor que la diferencias entre Q1 y el mínimo. Estos nos indican que el 25% de los valores superiores es tan más dispersos, que el 75% restante.

Al analizar el grafico de diagrama de cajas (Boxplot), se observa que no hay valores atípicos en el extremo inferior, y por eso el bigote inferior se extiende hasta el valor mínimo, 0.17. En cambio en el extremo superior vemos varios valores atípicos, representados por unos círculos sobre el bigote superior.  

Para detectar los valores atípicos, los bigotes se extendieron hasta un $Mínimo = Q1 - 1.5*IQR$, por debajo de Q1 y hasta un $Máximo = Q3 + 1.5*IQR$, por encima de Q3. Donde __IQR = 17__, __Q1 = 21__ y __Q3 = 38__; Entonces el $Mínimo=21–1.5*17=-4.5$, donde todos los valores menores a este valor son considerados atípicos, en nuestro caso como no hay valores menores que este, por eso el bigote se extiende hasta el mínimo valor de la variable; Los valores mayores al $Máximo=38+1.5*17=63.5$ serán considerados atípicos, que son los valores representados en el grafico por los puntos negros.  

Considerando lo anterior, a continuación se muestran los valores atípicos para la variable __Age__. __Donde Age > 63.5__:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Valores extremos encontrados en la variable Age donde Age > 63.5
sort(gf.boxplot$out, decreasing = FALSE)

```

No obstante, si revisamos los anteriores datos, las edades de los pasajeros comprendidas entre 64 y 80, son valores que perfectamente pueden darse. Es por ello que el manejo de estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.

Realizaremos un análisis de valores extremos para la variable numérica __Fare__, realizando un análisis por quartiles:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# generar los quartiles que representan la distribución del conjunto de datos
summary(titanic.data$Fare)

## Calculamos la relación inter quartil (IQR), Q3 - Q1 = IQR()
print(paste("Relación inter quartil (IQR): ",IQR(titanic.data$Fare)),quote = FALSE)

# Grafico de boxplot
gf.boxplot <- boxplot(titanic.data$Fare, main="Boxplot del precio del Boleto (Fare)",
ylab="Fare",col = "bisque")
```

Al inspeccionar las estadísticas arrojadas, para la variable __Fare__, el valor mínimo es 3.17 y el Máximo es 512.33. Si analisamos  la diferencia entre Q1 y el Mínimo es de 4.75, y la diferencia entre Q3 y el Máximo es 481.05; cómo podemos ver la diferencia de Q3 y el máximo es mayor que la diferencias entre Q1 y el mínimo. Estos nos indican que el 25% de los valores superiores es tan más dispersos, que el 75% restante.

Al analizar el grafico de diagrama de cajas (Boxplot), se observa que no hay valores atípicos en el extremo inferior, y por eso el bigote inferior se extiende hasta el valor mínimo, 3.17. En cambio en el extremo superior vemos varios valores atípicos, representados por unos círculos sobre el bigote superior.  

Para detectar los valores atípicos, los bigotes se extendieron hasta un $Mínimo = Q1 - 1.5*IQR$, por debajo de Q1 y hasta un $Máximo = Q3 + 1.5*IQR$, por encima de Q3. Donde __IQR = 23.35__, __Q1 = 7.93__ y __Q3 = 31.28__; Entonces el $Mínimo=7.93–1.5*23.35=-27.01$, donde todos los valores menores a este valor son considerados atípicos, en nuestro caso como no hay valores menores que este, por eso el bigote se extiende hasta el mínimo valor de la variable; Los valores mayores al $Máximo=31.28+1.5*23.35=66.31$ serán considerados atípicos, que son los valores representados en el grafico por los puntos negros.  

Considerando lo anterior, a continuación se muestran los valores atípicos para la variable __Fare__. __Donde Fare > 66.31__:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Valores extremos encontrados en la variable Fare donde Fare > 66.31
sort(gf.boxplot$out, decreasing = FALSE)
```

No obstante, si revisamos los anteriores datos, y miramos de forma aleatoria los precios de los Ticket podemos ver que los precios mas altos corresponde a los pasajeros de clase alta (Pclass = "Upper"), y son valores que perfectamente pueden darse. Es por ello que el manejo de estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Guardamos los datos de nuestro dataset (data.frame)  aun archivo en formato CSV
write.csv(titanic.data, "../datos/titanic.final.csv")
```


## Análisis de los datos

### Selección de los gurpos de datos que se quieren analizar / comparar

Vamos a realizar un análisis preliminar de las variables, para determinar su normalidad y su relación con survived, esto nos ayudará a realizar ejercicios posteriores para tratar de predecir qué pasajeros se salvaron del titanic y cuales no.

Las variables que vamos a analizar son sex, pclass, age, sibsp,parch,embarked,fare y su relación con survived, que es la variable dependiente que tratamos de predecir. El resto de variables como id, name, ticket o cabin son datos individuales de cada pasajero que no parece que vayan a aportar una información valiosa.

### Comprobación de la normalidad y homogeneidad de la varianza.

[Ver apartado 2.5](#apartado25)

### Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.  

[Ver apartado 2.5](#apartado25)


## Representación de los resultados a partir de tablas y gráficas.  
<a name="apartado25"></a>
Por claridad en el informe, en este apartado se compilan los 3 puntos anteriores (apartados 2.4.2 y 2.4.3) ya que se realizan las pruebas estadísticas así como los métodos de análisis pertinentes para determinar qué probabilidades tiene cada persona de haber sobrevivido al hundimiento del Titanic, además se representan las tablas y gráficas pertinentes para una mejor visualización de cada apartado del análisis.

Vamos a comenzar analizando la variable sex con respecto a survived, en este caso podemos realizar una tabla de contingencia. Al ser 2 variables categóricas no tiene sentido analizar la distribución.


```{r message= FALSE, warning=FALSE}
ggplot(titanic.data,aes(Sex,fill=Survived))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ggtitle("Survived by Sex")
```



  
Vemos cómo el porentaje de mujeres supervivientes es mucho mayor que el de hombres, esto lo podemos comprobar con una tabla de contingencia.

```{r message= FALSE, warning=FALSE}
tblSex<-table(titanic.data$Survived,titanic.data$Sex)
tblSex
```  

Efectivamente vemos cómo el sexo puede ser un factor determinante a la hora de realizar una predicción sobre la supervivencia.

Vamos a ejecutar el test chi-square para asegurar que existen diferencias significativas entre los grupos.

```{r message= FALSE, warning=FALSE}
 chisq.test(tblSex)
```
  
Efectivamente el test chi-square arroja un p-value bastante pequeño, lo que nos indica que existe una correlación entre estas variables, con lo que el sexo nos puede ayudar a discernir si una persona fue superviviente del titanic o no.

Hacemos el mismo análisis con la variable PClass.

```{r message= FALSE, warning=FALSE}
library(ggplot2)
ggplot(titanic.data,aes(Pclass,fill=Survived))+geom_bar() +labs(x="Pclass", y="Passengers")+ guides(fill=guide_legend(title=""))+ ggtitle("Survived by Pclass")
```


Vemos cómo existe también una diferencia grande en el porcentaje de supervivientes según el nivel económico de los pasajeros.

Vemos la tabla de contingencia.

```{r message= FALSE, warning=FALSE}
tblClass<-table(titanic.data$Survived,titanic.data$Pclass)
tblClass
``` 

Ejecutamos el test chi-squared para ver la independencia entre los casos.

```{r message= FALSE, warning=FALSE}
 chisq.test(tblClass)
```

En este caso también observamos diferencias significativas en la supervivencia según la variable class, el p-value de nuevo nos indica que debemos rechazar la hipótesis nula de independencia, con lo que vemos cierta correlación entre PClass y Survived.


Analizamos ahora la variable Sibsp de la misma forma.


```{r message= FALSE, warning=FALSE}
ggplot(titanic.data,aes(SibSp      ,fill=Survived))+geom_bar() +labs(x="Sibsp", y="Passengers")+ guides(fill=guide_legend(title=""))+ggtitle("Survived by SibSp")
```


Atendiendo al gráfico, vemos diferencias significativas en el porcentaje de supervivientes según el número de familiares que están en el barco.

Vamos a realizar al igual que en los casos anteriores la tabla de contingencia y el test chi-square.


```{r message= FALSE, warning=FALSE}

tblSibsp<-table(titanic.data$Survived,titanic.data$SibSp)
tblSibsp
```

Efectivamente se observa cómo el porcentaje de supervivencia varía bastante según el número de familiares en el barco.

```{r message= FALSE, warning=FALSE}
chisq.test(tblSibsp)
```

De nuevo el test chi-squared arroja cierta correlación entre estas variables, con lo que el número de parientes también puede ser una variable importante a la hora de predecir la supervivencia de una persona.


Repetimos el mismo análisis con la variable Parch (número de padres/hijos)

```{r message= FALSE, warning=FALSE}
ggplot(titanic.data,aes(Parch,fill=Survived))+geom_bar() +labs(x="Parch", y="Passengers")+ guides(fill=guide_legend(title=""))+ggtitle("Survived by Parch")
```

```{r message= FALSE, warning=FALSE}
tblParch<-table(titanic.data$Survived,titanic.data$Parch)
tblParch
``` 


Repetimos el test chi-squared 

```{r message= FALSE, warning=FALSE}
chisq.test(tblParch)
```

Estos datos también indican diferencias significativas en el la supervivencia con respecto al número de familiares.  

Repetimos el mismo análisis con el puerto de embarque

```{r message= FALSE, warning=FALSE}
ggplot(titanic.data,aes(Embarked,fill=Survived))+geom_bar() +labs(x="Embarked", y="Passengers")+ guides(fill=guide_legend(title=""))+ggtitle("Survived by Embarked")
```

Según el gráfico también existen diferencias significativas en el porcentaje de supervivientes según el puerto de embarque. Vamos a comprobarlo de nuevo con la tabla de contingencia y el test chi-squared.

```{r message= FALSE, warning=FALSE}
tblEmbarked<-table(titanic.data$Survived,titanic.data$Embarked)
tblEmbarked
``` 


```{r message= FALSE, warning=FALSE}
chisq.test(tblEmbarked)
```


El test chi-squared nos dice de nuevo que sí hay una relación entre el puerto de embarque y la supervivencia.  

Vamos a analizar la variable edad, en este caso se trata de una variable continua con lo que analizaremos su distribución y veremos si existen diferencias significativas en la media de edad de los supervivientes y los no supervivientes.

Vemos las distribuciones de la edad de los supervivientes y los no supervivientes en las siguientes gráficas.

```{r message= FALSE, warning=FALSE}

ggplot(titanic.data[titanic.data$Survived=="No",], aes(x=Age)) + 
  geom_density()+ ggtitle("Non Survivors Density")

ggplot(titanic.data[titanic.data$Survived=="Si",], aes(x=Age)) + 
  geom_density()+ ggtitle("Survivors Density")
```


Vemos en las gráficas de densidad que ninguna de las 2 sigue una distribución normal. Lo comprobamos con el test de Shapiro Wilk
```{r message= FALSE, warning=FALSE}
shapiro.test(titanic.data[titanic.data$Survived=="No",]$Age)
```
```{r message= FALSE, warning=FALSE}
shapiro.test(titanic.data[titanic.data$Survived=="Si",]$Age)
```

Efectivamente se comprueba que la variable edad no sigue una distribución normal. Vamos a comparar las varianzas entre las edades de ambos grupos.

```{r message= FALSE, warning=FALSE}
 fligner.test(Age ~ Survived, data = titanic.data) 
```

El p-value del test sugiere que existe homoceasticidad entre ambos grupos, es decir que la varianza entre las edades de los supervivientes y los no supervivientes es parecida.


Dado que existe homoceasticidad entre los grupos y que tenemos un número significativamente alto de muestras, por el teorema del límite central  podemos realizar un test t-student para comprobar las medias entre ambos grupos.

```{r message= FALSE, warning=FALSE}

t.test(Age ~ Survived,data=titanic.data,alternative="two.sided",var.equal=TRUE)
```

En este caso vemos cómo el p-value es menor a 0.05, con lo que podemos rechazar la hipótesis nula, las medias de edad entre supervivientes y no supervivietnes no son iguales, esto nos dice que la edad puede ser un elemento importante a la hora de clasificar los supervivientes de los no supervivientes.  

Vamos a repetir el mismo análisis con la variable Fare frente a Survived.

```{r message= FALSE, warning=FALSE}

ggplot(titanic.data[titanic.data$Survived=="No",], aes(x=Fare)) + 
  geom_density()+ ggtitle("Non Survivors Density")

ggplot(titanic.data[titanic.data$Survived=="Si",], aes(x=Fare)) + 
  geom_density()+ ggtitle("Survivors Density")


```



Vemos claramente que no hay normalidad en estas variables, vamos a realizar el test de homoceasticidad, como en el caso de la edad.




```{r message= FALSE, warning=FALSE}
 fligner.test(Fare ~ Survived, data = titanic.data) 
```
En este caso tampoco se observa homoceasticidad entre ambos grupos, debemos rechazar la hipótesis nula, las varianzas no son parecidas, con lo que para hacer una comparación entre los 2 grupos en este caso debemos usar un test no paramétrico de Wilcoxon ya que son grupos independientes.


```{r message= FALSE, warning=FALSE}
 wilcox.test(Fare ~ Survived, data = titanic.data)
```

No podemos rechazar la hipótesis nula, vemos que sí se observan diferencias significativas entre las tarifas pagadas por los supervivientes y los no supervivientes.

### Modelos predictivos.

Utilizaremos las variables anteriores para tratar de construir un modelo predictivo, en todas las variables estudiadas se ha observado cierta relación con la variable survived, con lo que en principio las usaremos en nuestros modelos.

Para realizar los análisis pertientes y tratar de obtener un modelo predictivo, vamos a obtener el dataset de test, seleccionando las filas desde 892 hasta 1309.

```{r message= FALSE, warning=FALSE}
titanic.test<- titanic.data[892:1309,]
```

Una vez tenemos el dataset de test preparado, vamos a ejecutar una regresión logística sobre los parámetros que hemos elegido, para ver cómo se comporta.


```{r message= FALSE, warning=FALSE}
logit =glm(formula=Survived ~  Sex+Pclass+Age+SibSp+Parch+Embarked+Fare, data=titanic.data[1:891,],family = binomial)
summary(logit)
```

Observamos que según el p-value las variables más importantes para diferenciar supervivientes de no supervivientes son Sex, PClass, Age, SibSp.


Realizamos una predicción sobre las mismas columnas de test, esto nos dará la probabilidad de supervivencia, consideramos supervivientes los que tengan una probabilidad mayor de 0.5

```{r message= FALSE, warning=FALSE}
prediction<-predict(logit,newdata=titanic.test[,!(colnames(titanic.test) %in% c("Survived"))],type="response")

surv_prediction = ifelse(prediction>0.5,1,0)

table(surv_prediction)
```

Para comparar los resultados realizamos la matriz de confusión con los valores que tenemos en test.

```{r message= FALSE, warning=FALSE}
conf_Matrix<-table(surv_prediction,titanic.test$Survived)
conf_Matrix
porcentaje_correcto<-100 * sum(diag(conf_Matrix)) / sum(conf_Matrix)
porcentaje_correcto
```

Observamos cómo por este método se han clasificado correctamente 250 no supervivientes y 139 supervivientes. 

Esto hace una fiabilidad de la predicción del 93.06%

Vamos a intentar clasificar y predecir los supervivientes mediante un árbol de decisión. Utilizamos la función rpart.

```{r message= FALSE, warning=FALSE}

library(rpart)
model_cart<-rpart(Survived~Sex+Pclass+Age+SibSp+Parch+Embarked+Fare,data=titanic.data[1:891,],method="class")
model_cart
```


Vamos a mostrar el árbol

```{r echo=TRUE, message=FALSE, warning=FALSE}
par(xpd = NA)

plot(model_cart)
text(model_cart,use.n=TRUE)
```

Vamos a validar este modelo con el set de datos de test:
```{r echo=TRUE, message=FALSE, warning=FALSE}

predicted.classes <- predict( model_cart, titanic.test[,!(colnames(titanic.test) %in% c("Survived"))], type="class" )

```

Vamos a validar el resultado de la predicción con el árbol de decisión

```{r message= FALSE, warning=FALSE}
conf_Matrix<-table(predicted.classes,titanic.test$Survived)
conf_Matrix
porcentaje_correcto<-100 * sum(diag(conf_Matrix)) / sum(conf_Matrix)
porcentaje_correcto
```


Observamos que con este método disminuyo el porcentaje de acierto en la predicción a un 92.34%. El mayor problema son los falsos positivos, es decir, que el algoritmo ha clasificado como supervivientes 23 casos que en realidad son no supervivientes.  

Para ajustar esto podemos asignar penalizaciones a los falsos negativos y falsos positivos, penalizando más lo que nos interesa.Vamos a repetir el método ajustando las penalizaciones con el parámetro loss.  

```{r message= FALSE, warning=FALSE}

library(rpart)
model_cart<-rpart(Survived~Sex+Pclass+Age+SibSp+Parch+Embarked+Fare,data=titanic.data[1:891,],method="class",parms=list(loss=c(0,1.20,1,0)))
model_cart
```

Mostramos el nuevo árbol.

```{r echo=TRUE, message=FALSE, warning=FALSE}
par(xpd = NA)

plot(model_cart)
text(model_cart,use.n=TRUE)
```

Realizamos la predicción.

```{r echo=TRUE, message=FALSE, warning=FALSE}

predicted.classes <- predict( model_cart, titanic.test[,!(colnames(titanic.test) %in% c("Survived"))], type="class" )

```

Hallamos la matriz de confusión.

```{r message= FALSE, warning=FALSE}
conf_Matrix<-table(predicted.classes,titanic.test$Survived)
conf_Matrix
porcentaje_correcto<-100 * sum(diag(conf_Matrix)) / sum(conf_Matrix)
porcentaje_correcto
```


Después de realizar el ajuste con los pesos, vemos que obtenemos un árbol menos efectivo ya que llegamos a un 88.27% de clasificación correcta.


Por último vamos a intentar clasificar mediante un modelo de clústering por el algoritmo mclust, que es un algoritmo basado en modelos.
 En este caso usa un modelo de mezclas gaussianas, que estima la probabilidad de que un dato pertenezca a cada una de las distribuciones, definidas por su media y su varianza. Para asignar los datos a las distribuciones usa el algoritmo de Esperanza-Maximización.
 
Seleccionamos las columnas de los anteriores modelos e indicamos que sólo queremos 2 grupos.

```{r message= FALSE, warning=FALSE}
train<-titanic.data[1:891,!(colnames(titanic.test) %in% c("Survived"))]

levels(train$Sex)<-c(0,1)

train$Sex<-as.numeric(as.character(train$Sex))

#train<-train[train$Embarked!="",]
#levels(train$Embarked)<-droplevels(train$Embarked)
levels(train$Embarked)<-c(0,1,2)
train$Embarked<-as.numeric(as.character(train$Embarked))
levels(train$Pclass)<-c(0,1,2)
train$Pclass<-as.numeric(as.character(train$Pclass))


library(mclust)
fit <- Mclust(train,G=1:2)
summary(fit)


```



Vamos a realizar la predicción sobre test, para ello debemos transformar las columnas a numérico, de la misma manera que en train.

```{r message= FALSE, warning=FALSE}
#install.packages("clue")
mtest<-titanic.test



levels(mtest$Sex)<-c(0,1)

mtest$Sex<-as.numeric(as.character(mtest$Sex))

levels(mtest$Embarked)<-c(0,1,2)
mtest$Embarked<-as.numeric(as.character(mtest$Embarked))

levels(mtest$Pclass)<-c(0,1,2)
mtest$Pclass<-as.numeric(as.character(mtest$Pclass))

mpredict<-predict.Mclust(fit,mtest[,!(colnames(titanic.test) %in% c("Survived"))])


```

Vamos a evaluar el algoritmo de la misma forma que antes, con la matriz de confusión.

```{r message= FALSE, warning=FALSE}



conf_Matrix<-table(mpredict$classification,mtest$Survived)
conf_Matrix
porcentaje_correcto<-100 * sum(diag(conf_Matrix)) / sum(conf_Matrix)
porcentaje_correcto


```

En este caso vemos que el algoritmo se queda en un 46.65% de efectividad, bastante menor que los anteriores.


## Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?  

Hemos comprobado cómo las variables del dataset que habíamos elegido pueden servir para resolver el problema que es predecir la probabilidad de supervivencia de una persona en el hundimiento del Titanic según sus características.

Primero hemos determinado mediante pruebas estadísticas si existe relación entre las variables del dataset y la variable que indica si una persona es superviviente o no, hemos visto que todas las variables pueden ayudarnos en mayor o menor medida a discernir si una persona fue o no superviviente, aunque unas con más significación que otras.

En cuanto a los modelos predictivos, la regresión logística obtiene el mejor resultado con un 93% de acierto en los datos de test, sin embargo el árbol de decisión dio un 92% de acierto, aunque se ajustaron las penalizaciones adecuadamente no mejoro los resultados con un 88% de eficacia En cuanto a los modelos de clústering, vemos cómo no se ajustan bien para este caso ya que su eficacia se queda en un 46%.


## Tabla de contribuciones al trabajo


Todos los integrantes de este grupo contribuyeron en el desarrollo y solución de cada uno de los apartados que componen la PRA2.  

|  Contribuciones |   Firma |
|---|---|
| Investigación previa  |  RT, DO  |
| Redacción de las respuestas  | RT, DO  |
| Desarrollo código  |  RT, DO  |

## Miembros del equipo

|  Nombre |   Correo |   Iniciales |
|---|---|---|
| Reison Torres Urina |  rtorresu\@uoc.edu  | RT |
| David Ordorica Rubiano |  dordorica\@uoc.edu  | DO | 


# Recursos

1. Brett, Lantz. (2013). "Machine Learning with R". (ISBN: 978-1-78216-214-8). UK: Packt Publishing Ltd.

2. Salazar, Camila. (2018, 13 de febrero). “Cálculo de correlaciones”. RPubs [artículo en línea]. [Fecha de consulta: 26 de diciembre del 2019]. <https://rpubs.com/camilamila/correlaciones>

3. Sanguesa, R. (n.d.). Preparación de datos. Universitat Oberta de Catalunya.

4. Subirats, Laia. (n.d.). Introducción a la limpieza y análisis de los datos. Universitat Oberta de Catalunya.
